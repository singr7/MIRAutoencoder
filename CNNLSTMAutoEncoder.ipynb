{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNLSTMAutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHP4BgQ4doy67sfPyeQf5B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singr7/MIRAutoencoder/blob/master/CNNLSTMAutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9JqXiXhqdkN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORCKRmYPHk-z"
      },
      "source": [
        "#Mount the google drive\n",
        "#Create list of numpy files for western and indian dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPnD6kkyHfx8",
        "outputId": "3862d529-1bee-4805-a8ec-d2d4cdacb324"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "western_files = []\n",
        "western_file_dir = \"/content/drive/My Drive/MusicResearchColabNB/Western_numpy\"\n",
        "for r,d, fileList in os.walk(western_file_dir):\n",
        "  for file in fileList:\n",
        "    western_files.append(os.path.join(r,file))\n",
        "\n",
        "indian_files = []\n",
        "indian_file_dir = \"/content/drive/My Drive/MusicResearchColabNB/IndianDataset/Indian_numpy\"\n",
        "for r,d, fileList in os.walk(indian_file_dir):\n",
        "  for file in fileList:\n",
        "    indian_files.append(os.path.join(r,file))\n",
        "\n",
        "print(len(western_files))\n",
        "print(len(indian_files))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "7592\n",
            "2008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMQbF-ylLmdK"
      },
      "source": [
        "# Balance the western dataset by taking files equal to Indian dataset files = 2008"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXHKJAOLL-iX",
        "outputId": "69de3acb-83c1-495b-83d8-6191ddfa77a2"
      },
      "source": [
        "import random \n",
        "#randomize the selection. To avoid getting a different random sample with every run, use seed\n",
        "random.seed(23)\n",
        "bal_western_files = random.sample(western_files,2008)\n",
        "len(bal_western_files)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBwpwaTX3Jo"
      },
      "source": [
        "#Define configuration class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP4323imT53f"
      },
      "source": [
        "class Configuration:\n",
        "  seq_len = 200  # taking half of the original timesteps extracted \n",
        "  input_dim = 26  #num of mels\n",
        "  embedding_dim = 64\n",
        "  batch_size = 2\n",
        "  base_dir = \"/content/drive/My Drive/MusicResearchColabNB/vajra/westernAE\"   # need to be edited..\n",
        "  loss_function = torch.nn.MSELoss(reduction='sum')\n",
        "  lr=1e-3  # I edited it from 1e-3 to 1e-5\n",
        "  n_epochs = 6\n",
        "  model_file = \"/content/drive/My Drive/MusicResearchColabNB/vajra/westernAE/models/mel.pkl\"  #need need edits\n",
        "  results_dir = os.path.join(base_dir, \"./results\")  # may need edits\n",
        "  checkpoint_model_file = \"/content/drive/My Drive/MusicResearchColabNB/vajra/westernAE/models/mel_checkpoint.pkl\" #may need edits\n",
        "  kernel_size = 3  #why?\n",
        "  k_folds = 10 "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RALRBXgZZBA"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, seq_len, n_features, embedding_dim=64, kernel_size=3, stride=1):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.seq_len, self.n_features = seq_len, n_features\n",
        "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
        "\n",
        "\n",
        "    self.conv = nn.Conv1d(in_channels=seq_len,out_channels=seq_len,kernel_size=kernel_size,stride=stride, groups=seq_len)\n",
        "    conv_op_dim = int(((n_features - kernel_size)/ stride) + 1)\n",
        "\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=conv_op_dim,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=self.hidden_dim,\n",
        "      hidden_size=embedding_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = x.reshape((1, self.seq_len, self.n_features))\n",
        "   # print('In Encoder')\n",
        "   # print(x.shape)\n",
        "    x = self.conv(x)\n",
        "    x, (_, _) = self.rnn1(x)\n",
        "    x, (hidden_n, _) = self.rnn2(x)\n",
        "    return x"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkW-A8TzZdGT"
      },
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, seq_len, embedding_dim=64, n_features=26):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.seq_len, self.embedding_dim = seq_len, embedding_dim\n",
        "    self.hidden_dim, self.n_features = 2 * embedding_dim, n_features\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=embedding_dim,\n",
        "      hidden_size=embedding_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=embedding_dim,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.output_layer = nn.Linear(self.hidden_dim * self.seq_len, n_features * self.seq_len)\n",
        "  def forward(self, x):\n",
        "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
        "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
        "    #print(\"in decoder\", x.shape)\n",
        "    x = x.contiguous()\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.output_layer(x)\n",
        "    return x.reshape(x.shape[0],self.seq_len, self.n_features)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mqrvU5MZfEA"
      },
      "source": [
        "class RecurrentAutoencoder(torch.nn.Module):\n",
        "  def __init__(self, seq_len, n_features, embedding_dim=64, device='cpu'):\n",
        "    super(RecurrentAutoencoder, self).__init__()\n",
        "    self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
        "    self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRQ-t9aNZiUD",
        "outputId": "bf54ab9a-9c18-469a-f084-dae15de045a4"
      },
      "source": [
        "x = torch.randn(5, 26, 400)\n",
        "print(x.shape)\n",
        "x = x.permute(0, 2, 1)\n",
        "print(x.shape)\n",
        "\n",
        "encoder = Encoder(400, 26, embedding_dim=64, kernel_size=3, stride=1)\n",
        "encoded = encoder(x)\n",
        "print(encoded.shape)\n",
        "\n",
        "decoder = Decoder(400, 64, 26)\n",
        "decoded = decoder(encoded)\n",
        "print(decoded.shape)\n",
        "\n",
        "rae = RecurrentAutoencoder(400, 26, 64)\n",
        "output = rae(x)\n",
        "\n",
        "print(output.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 26, 400])\n",
            "torch.Size([5, 400, 26])\n",
            "In Encoder\n",
            "torch.Size([5, 400, 26])\n",
            "torch.Size([5, 400, 64])\n",
            "in decoder torch.Size([5, 400, 128])\n",
            "torch.Size([5, 400, 26])\n",
            "In Encoder\n",
            "torch.Size([5, 400, 26])\n",
            "in decoder torch.Size([5, 400, 128])\n",
            "torch.Size([5, 400, 26])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDpec6ICZnKN"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "\n",
        "class CustomDatasetMel(Dataset):\n",
        "\n",
        "    def __init__(self, dataList):\n",
        "        self.data = dataList\n",
        "        #self.labels = labelList\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        import numpy as np\n",
        "        fileName = self.data[index]\n",
        "        \n",
        "        mel_spect = np.load(fileName)\n",
        "        data = torch.tensor(mel_spect[:,:200], dtype=torch.float)\n",
        "        data = data.permute(1, 0)\n",
        "        #data = torch.unsqueeze(data, dim =0)\n",
        "\n",
        "        #label = torch.tensor(self.labels[index])\n",
        "        return data"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAv1gLc6Zwwr",
        "outputId": "bb0d748e-6ff5-48d5-ea7f-db58cf0d5ff0"
      },
      "source": [
        "import copy\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "class TrainingWrapper:\n",
        "\n",
        "  def __init__(self, config, training_loader, test_loader, device, val_loader=None):\n",
        "    self.config = config\n",
        "    self.training_loader = training_loader\n",
        "    self.test_loader = test_loader\n",
        "    self.val_loader = val_loader\n",
        "    self.device = device\n",
        "    self.model = RecurrentAutoencoder(self.config.seq_len, self.config.input_dim, self.config.embedding_dim, device=self.device)\n",
        "    self.model = self.model.to(self.device)\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.config.lr)\n",
        "    self.criterion = self.config.loss_function.to(self.device)\n",
        "    self.history = dict(train=[], val=[], cross_val=[])\n",
        "    self.best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "    self.best_loss = 10000.0\n",
        "    #print(self.config.base_dir + self.config.model_file)\n",
        "    torch.save(self.model.state_dict(),  self.config.model_file)\n",
        "    #self.cross = cross\n",
        "    \n",
        "\n",
        "  def combine_images(self, generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "\n",
        "  def show_reconstruction(self, test_loader, n_images):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "\n",
        "    self.model.eval()\n",
        "    for x, _ in self.test_loader:\n",
        "        x = x[:min(n_images, x.size(0))].to(self,device)\n",
        "        _, x_recon = self.model(x)\n",
        "        data = np.concatenate([x.data.cpu(), x_recon.data.cpu()])\n",
        "        img = self.combine_images(np.transpose(data, [0, 2, 3, 1]))\n",
        "        image = img * 255\n",
        "        Image.fromarray(image.astype(np.uint8)).save(self.config.base_dir + \"/real_and_recon.png\")\n",
        "        print()\n",
        "        print('Reconstructed images are saved to %s/real_and_recon.png' % self.config.base_dir)\n",
        "        print('-' * 70)\n",
        "        plt.imshow(plt.imread(self.config.base_dir + \"/real_and_recon.png\", ))\n",
        "        plt.show()\n",
        "        break\n",
        "\n",
        "  def visualizeTraining(self, epoch, trn_losses, tst_losses, val_losses, save_dir, cross):\n",
        "    # visualize the loss as the network trained\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    plt.plot(range(0, len(trn_losses)), trn_losses, label='Training Loss')\n",
        "    if tst_losses:\n",
        "      plt.plot(range(0, len(tst_losses)), tst_losses, label='Validation Loss')\n",
        "    if val_losses:\n",
        "      plt.plot(range(0, len(val_losses)), val_losses, label='Cross Validation Loss')\n",
        "\n",
        "    minposs = tst_losses.index(min(tst_losses))\n",
        "    plt.axvline(minposs, linestyle='--', color='r', label='Early Stopping Checkpoint')\n",
        "\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    # plt.ylim(0, 0.5)  # consistent scale\n",
        "    # plt.xlim(0, len(trn_losses))  # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig(os.path.join(save_dir , 'loss_plot_{}.png'.format(cross)), bbox_inches='tight')\n",
        "\n",
        "  def train(self):\n",
        "    for epoch in range(1, self.config.n_epochs + 1):\n",
        "      self.model = self.model.train()\n",
        "      train_losses = []\n",
        "\n",
        "      for i, (x, y) in enumerate(self.training_loader):\n",
        "        self.optimizer.zero_grad()\n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        output = self.model(x)\n",
        "        loss = self.criterion(output, x)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "        print(\"in training loop, epoch {}, step {}, the loss is {}\".format(epoch, i, loss.item()))\n",
        "\n",
        "      val_losses = []\n",
        "      self.model = self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(self.test_loader):\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          output = self.model(x)\n",
        "          loss = self.criterion(output, x)\n",
        "          val_losses.append(loss.item())\n",
        "\n",
        "\n",
        "      cross_val_losses = []\n",
        "      self.model = self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(self.val_loader):\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          output = self.model(x)\n",
        "          loss = self.criterion(output, x)\n",
        "          cross_val_losses.append(loss.item())\n",
        "\n",
        "      train_loss = np.mean(train_losses)\n",
        "      val_loss = np.mean(val_losses)\n",
        "      cross_val_loss = np.mean(cross_val_losses)\n",
        "\n",
        "\n",
        "      self.history['train'].append(train_loss)\n",
        "      self.history['val'].append(val_loss)\n",
        "      self.history['cross_val'].append(cross_val_loss)\n",
        "\n",
        "      if val_loss < self.best_loss:\n",
        "        self.best_loss = val_loss\n",
        "        self.best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "      if epoch % 2 == 0:\n",
        "        self.visualizeTraining(epoch, trn_losses= self.history['train'], tst_losses=self.history['val'], val_losses =self.history['cross_val'], save_dir=self.config.base_dir + \"/results\", cross= self.cross)\n",
        "        torch.save(self.model.state_dict(), self.config.base_dir + self.config.checkpoint_model_file + \"_\" + str(self.cross))\n",
        "      print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
        "    self.model.load_state_dict(self.best_model_wts)\n",
        "    torch.save(self.model.state_dict(), self.config.base_dir + self.config.model_file)\n",
        "    return self.model.eval(), self.history\n",
        "\n",
        "  \n",
        "class TestingWrapper:\n",
        "  def __init__(self, config, device):\n",
        "    self.config = config\n",
        "    self.device = device\n",
        "    self.model = RecurrentAutoencoder(self.config.seq_len, self.config.input_dim, self.config.embedding_dim, device=self.device)\n",
        "    PATH = self.config.base_dir + self.config.checkpoint_model_file\n",
        "    print(PATH)\n",
        "    self.model.load_state_dict(torch.load(PATH, map_location=self.device))\n",
        "    self.model = self.model.to(self.device)\n",
        "\n",
        "  def combine_images(self, generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "\n",
        "  def show_reconstruction(self, test_loader, n_images):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "\n",
        "    self.model.eval()\n",
        "    for x, _ in test_loader:\n",
        "      x = x[:min(n_images, x.size(0))].to(self.device)\n",
        "      x_recon = self.model(x)\n",
        "      data = np.concatenate([x.data.cpu(), x_recon.data.cpu()])\n",
        "      img = self.combine_images(np.transpose(data, [0, 2, 3, 1]))\n",
        "      image = img * 255\n",
        "      Image.fromarray(image.astype(np.uint8)).save(self.config.base_dir + \"/real_and_recon.png\")\n",
        "      print()\n",
        "      print('Reconstructed images are saved to %s/real_and_recon.png' % self.config.base_dir)\n",
        "      print('-' * 70)\n",
        "      plt.imshow(plt.imread(self.config.base_dir + \"/real_and_recon.png\", ))\n",
        "      plt.show()\n",
        "      break\n",
        "\n",
        "  def save_reconstruction(self, test_loader):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    import uuid\n",
        "\n",
        "\n",
        "    self.model.eval()\n",
        "    with torch.no_grad(): \n",
        "      fileCount = 0\n",
        "      for x, _ in test_loader:\n",
        "        x = x.to(self.device)\n",
        "        x_recon = self.model(x)\n",
        "        x_recon = x_recon.data.cpu().detach().numpy()\n",
        "        for mel in x_recon:\n",
        "          #print(mel.shape)\n",
        "          unique_filename = str(uuid.uuid4())\n",
        "          filename = self.config.base_dir + \"/reconstruction/\" + unique_filename + \".npy\"\n",
        "          np.save(filename, mel)\n",
        "          fileCount = fileCount + 1\n",
        "          print(\"saving file {} at index {}\".format(filename, fileCount))\n",
        "\n",
        "mode = 'train'\n",
        "data = \"mel\"\n",
        "#data = \"mnist\"\n",
        "config = Configuration()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import random\n",
        "import os\n",
        "\n",
        "def seed_everything(seed=1234):\n",
        "  \n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def visualizeTraining(epoch, trn_losses, tst_losses, val_losses, save_dir):\n",
        "    # visualize the loss as the network trained\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    plt.plot(range(0, len(trn_losses)), trn_losses, label='Training Loss')\n",
        "    if tst_losses:\n",
        "      plt.plot(range(0, len(tst_losses)), tst_losses, label='Validation Loss')\n",
        "    if val_losses:\n",
        "      plt.plot(range(0, len(val_losses)), val_losses, label='Cross Validation Loss')\n",
        "\n",
        "    minposs = tst_losses.index(min(tst_losses))\n",
        "    plt.axvline(minposs, linestyle='--', color='r', label='Early Stopping Checkpoint')\n",
        "\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    # plt.ylim(0, 0.5)  # consistent scale\n",
        "    # plt.xlim(0, len(trn_losses))  # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig(os.path.join(save_dir , 'loss_plot_{}.png'.format(\"MEAN\")), bbox_inches='tight')\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "train_data = bal_western_files\n",
        "#labels = [1] * len(bal_western_files)\n",
        "\n",
        "val_data = indian_files\n",
        "#val_labels = [1] * len(indian_files)\n",
        "\n",
        "train_loss_mean_list = []\n",
        "test_loss_mean_list = []\n",
        "val_loss_mean_list = []\n",
        "\n",
        "# Cross validation runs\n",
        "# use sklearn KFolds\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=config.k_folds , shuffle=True)\n",
        "\n",
        "train_dataset = CustomDatasetMel(train_data)\n",
        "val_dataset = CustomDatasetMel(val_data)\n",
        "#Load the cross val dataset which is Full Indian dataset\n",
        "#It is identical for all K-folds\n",
        "crossval_loader = torch.utils.data.DataLoader(\n",
        "                      val_dataset,\n",
        "                      batch_size=config.batch_size, \n",
        "                      sampler=SequentialSampler(val_dataset), \n",
        "                      drop_last=False)  \n",
        "\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(train_dataset)):\n",
        "    # Print\n",
        "  print(f'FOLD {fold}')\n",
        "  print('--------------------------------')\n",
        "    \n",
        "    # Sample elements randomly from a given list of ids, no replacement.\n",
        "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "  test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "  \n",
        "    # Define data loaders for training and testing data in this fold\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "                      train_dataset, \n",
        "                      batch_size=config.batch_size,\n",
        "                      sampler=train_subsampler,\n",
        "                      drop_last=False)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "                      train_dataset,\n",
        "                      batch_size=config.batch_size,\n",
        "                      sampler=test_subsampler,\n",
        "                      drop_last=False)\n",
        "    \n",
        "  print(\"length of of train_loader is {} & length of traindataset is {}\".format(len(train_loader),len(train_dataset)))\n",
        "  print(\"length of of test_loader is {}\".format(len(test_loader)))\n",
        "  print(\"length of of val_loader is {}\".format(len(crossval_loader)))\n",
        "    \n",
        "  if mode==\"train\":\n",
        "    trainingWrapper = TrainingWrapper(config=config, training_loader=train_loader, test_loader=test_loader, device=device, val_loader=crossval_loader)\n",
        "    model, history = trainingWrapper.train()\n",
        "    train_loss_mean_list.append(history['train'])\n",
        "    test_loss_mean_list.append(history['val'])\n",
        "    val_loss_mean_list.append(history['cross_val'])\n",
        "    \n",
        "\n",
        "    if data==\"mnist\":\n",
        "      #trainingWrapper.show_reconstruction(test_loader=test_loader, n_images=50)\n",
        "      pass\n",
        "\n",
        "  elif mode==\"test\":\n",
        "    testWrapper = TestingWrapper(config=config, device=device)\n",
        "    testWrapper.save_reconstruction(test_loader)\n",
        "  \n",
        "  train_loss_mean_list = np.mean(train_loss_mean_list, axis=0)\n",
        "  test_loss_mean_list = np.mean(test_loss_mean_list, axis=0)\n",
        "  val_loss_mean_list = np.mean(val_loss_mean_list, axis=0)\n",
        "  visualizeTraining(0, train_loss_mean_list, test_loss_mean_list, val_loss_mean_list, save_dir = config.base_dir + \"/results\")\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "length of of train_loader is 904 & length of traindataset is 2008\n",
            "length of of test_loader is 101\n",
            "length of of val_loader is 1004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([200, 26])) that is different to the input size (torch.Size([1, 200, 26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "in training loop, epoch 1, step 0, the loss is 9853472.0\n",
            "in training loop, epoch 1, step 1, the loss is 4005032.0\n",
            "in training loop, epoch 1, step 2, the loss is 6652195.5\n",
            "in training loop, epoch 1, step 3, the loss is 1634187.25\n",
            "in training loop, epoch 1, step 4, the loss is 3382299.25\n",
            "in training loop, epoch 1, step 5, the loss is 2438443.5\n",
            "in training loop, epoch 1, step 6, the loss is 1457719.0\n",
            "in training loop, epoch 1, step 7, the loss is 556820.5\n",
            "in training loop, epoch 1, step 8, the loss is 1568167.375\n",
            "in training loop, epoch 1, step 9, the loss is 1516203.375\n",
            "in training loop, epoch 1, step 10, the loss is 2243941.75\n",
            "in training loop, epoch 1, step 11, the loss is 1374629.5\n",
            "in training loop, epoch 1, step 12, the loss is 2388887.25\n",
            "in training loop, epoch 1, step 13, the loss is 313735.875\n",
            "in training loop, epoch 1, step 14, the loss is 382394.34375\n",
            "in training loop, epoch 1, step 15, the loss is 680324.125\n",
            "in training loop, epoch 1, step 16, the loss is 909154.5\n",
            "in training loop, epoch 1, step 17, the loss is 461340.8125\n",
            "in training loop, epoch 1, step 18, the loss is 2556593.25\n",
            "in training loop, epoch 1, step 19, the loss is 343232.03125\n",
            "in training loop, epoch 1, step 20, the loss is 358361.0\n",
            "in training loop, epoch 1, step 21, the loss is 537759.0625\n",
            "in training loop, epoch 1, step 22, the loss is 562912.625\n",
            "in training loop, epoch 1, step 23, the loss is 1157288.125\n",
            "in training loop, epoch 1, step 24, the loss is 3605845.5\n",
            "in training loop, epoch 1, step 25, the loss is 777571.4375\n",
            "in training loop, epoch 1, step 26, the loss is 612836.125\n",
            "in training loop, epoch 1, step 27, the loss is 1210294.75\n",
            "in training loop, epoch 1, step 28, the loss is 470730.8125\n",
            "in training loop, epoch 1, step 29, the loss is 521848.8125\n",
            "in training loop, epoch 1, step 30, the loss is 988108.125\n",
            "in training loop, epoch 1, step 31, the loss is 1111136.625\n",
            "in training loop, epoch 1, step 32, the loss is 1517846.125\n",
            "in training loop, epoch 1, step 33, the loss is 266413.21875\n",
            "in training loop, epoch 1, step 34, the loss is 349001.8125\n",
            "in training loop, epoch 1, step 35, the loss is 270534.5\n",
            "in training loop, epoch 1, step 36, the loss is 1368962.0\n",
            "in training loop, epoch 1, step 37, the loss is 1385163.5\n",
            "in training loop, epoch 1, step 38, the loss is 1106914.75\n",
            "in training loop, epoch 1, step 39, the loss is 1218902.125\n",
            "in training loop, epoch 1, step 40, the loss is 790893.3125\n",
            "in training loop, epoch 1, step 41, the loss is 458612.90625\n",
            "in training loop, epoch 1, step 42, the loss is 354027.1875\n",
            "in training loop, epoch 1, step 43, the loss is 288446.25\n",
            "in training loop, epoch 1, step 44, the loss is 704686.375\n",
            "in training loop, epoch 1, step 45, the loss is 1302802.875\n",
            "in training loop, epoch 1, step 46, the loss is 7972392.0\n",
            "in training loop, epoch 1, step 47, the loss is 455836.25\n",
            "in training loop, epoch 1, step 48, the loss is 959365.9375\n",
            "in training loop, epoch 1, step 49, the loss is 918151.6875\n",
            "in training loop, epoch 1, step 50, the loss is 782246.5\n",
            "in training loop, epoch 1, step 51, the loss is 869003.8125\n",
            "in training loop, epoch 1, step 52, the loss is 283206.4375\n",
            "in training loop, epoch 1, step 53, the loss is 249904.953125\n",
            "in training loop, epoch 1, step 54, the loss is 726455.375\n",
            "in training loop, epoch 1, step 55, the loss is 289391.21875\n",
            "in training loop, epoch 1, step 56, the loss is 752262.75\n",
            "in training loop, epoch 1, step 57, the loss is 2910925.5\n",
            "in training loop, epoch 1, step 58, the loss is 272164.46875\n",
            "in training loop, epoch 1, step 59, the loss is 333342.09375\n",
            "in training loop, epoch 1, step 60, the loss is 857146.6875\n",
            "in training loop, epoch 1, step 61, the loss is 320228.90625\n",
            "in training loop, epoch 1, step 62, the loss is 462215.6875\n",
            "in training loop, epoch 1, step 63, the loss is 279977.6875\n",
            "in training loop, epoch 1, step 64, the loss is 266247.1875\n",
            "in training loop, epoch 1, step 65, the loss is 382616.5\n",
            "in training loop, epoch 1, step 66, the loss is 529707.125\n",
            "in training loop, epoch 1, step 67, the loss is 469328.53125\n",
            "in training loop, epoch 1, step 68, the loss is 743508.0\n",
            "in training loop, epoch 1, step 69, the loss is 398341.125\n",
            "in training loop, epoch 1, step 70, the loss is 750553.25\n",
            "in training loop, epoch 1, step 71, the loss is 323774.90625\n",
            "in training loop, epoch 1, step 72, the loss is 231681.484375\n",
            "in training loop, epoch 1, step 73, the loss is 844801.875\n",
            "in training loop, epoch 1, step 74, the loss is 416008.59375\n",
            "in training loop, epoch 1, step 75, the loss is 483927.8125\n",
            "in training loop, epoch 1, step 76, the loss is 616440.0\n",
            "in training loop, epoch 1, step 77, the loss is 348241.375\n",
            "in training loop, epoch 1, step 78, the loss is 95408.6015625\n",
            "in training loop, epoch 1, step 79, the loss is 737539.375\n",
            "in training loop, epoch 1, step 80, the loss is 431867.46875\n",
            "in training loop, epoch 1, step 81, the loss is 139236.171875\n",
            "in training loop, epoch 1, step 82, the loss is 165176.796875\n",
            "in training loop, epoch 1, step 83, the loss is 497842.71875\n",
            "in training loop, epoch 1, step 84, the loss is 917347.5\n",
            "in training loop, epoch 1, step 85, the loss is 242107.703125\n",
            "in training loop, epoch 1, step 86, the loss is 372214.375\n",
            "in training loop, epoch 1, step 87, the loss is 378868.625\n",
            "in training loop, epoch 1, step 88, the loss is 193411.703125\n",
            "in training loop, epoch 1, step 89, the loss is 1044462.125\n",
            "in training loop, epoch 1, step 90, the loss is 422416.375\n",
            "in training loop, epoch 1, step 91, the loss is 408073.34375\n",
            "in training loop, epoch 1, step 92, the loss is 737177.75\n",
            "in training loop, epoch 1, step 93, the loss is 1664177.875\n",
            "in training loop, epoch 1, step 94, the loss is 1434229.5\n",
            "in training loop, epoch 1, step 95, the loss is 226761.875\n",
            "in training loop, epoch 1, step 96, the loss is 835862.3125\n",
            "in training loop, epoch 1, step 97, the loss is 1012819.8125\n",
            "in training loop, epoch 1, step 98, the loss is 671980.875\n",
            "in training loop, epoch 1, step 99, the loss is 315614.96875\n",
            "in training loop, epoch 1, step 100, the loss is 532653.4375\n",
            "in training loop, epoch 1, step 101, the loss is 458908.96875\n",
            "in training loop, epoch 1, step 102, the loss is 251833.375\n",
            "in training loop, epoch 1, step 103, the loss is 109170.1484375\n",
            "in training loop, epoch 1, step 104, the loss is 551781.5\n",
            "in training loop, epoch 1, step 105, the loss is 1335190.875\n",
            "in training loop, epoch 1, step 106, the loss is 410402.125\n",
            "in training loop, epoch 1, step 107, the loss is 359666.21875\n",
            "in training loop, epoch 1, step 108, the loss is 191942.1875\n",
            "in training loop, epoch 1, step 109, the loss is 232549.5625\n",
            "in training loop, epoch 1, step 110, the loss is 351431.96875\n",
            "in training loop, epoch 1, step 111, the loss is 1198655.5\n",
            "in training loop, epoch 1, step 112, the loss is 246402.953125\n",
            "in training loop, epoch 1, step 113, the loss is 761742.125\n",
            "in training loop, epoch 1, step 114, the loss is 325283.3125\n",
            "in training loop, epoch 1, step 115, the loss is 570805.875\n",
            "in training loop, epoch 1, step 116, the loss is 602537.9375\n",
            "in training loop, epoch 1, step 117, the loss is 681215.5625\n",
            "in training loop, epoch 1, step 118, the loss is 630944.9375\n",
            "in training loop, epoch 1, step 119, the loss is 318098.0\n",
            "in training loop, epoch 1, step 120, the loss is 518892.5\n",
            "in training loop, epoch 1, step 121, the loss is 196463.6875\n",
            "in training loop, epoch 1, step 122, the loss is 437612.75\n",
            "in training loop, epoch 1, step 123, the loss is 572153.875\n",
            "in training loop, epoch 1, step 124, the loss is 284186.8125\n",
            "in training loop, epoch 1, step 125, the loss is 581617.875\n",
            "in training loop, epoch 1, step 126, the loss is 532086.625\n",
            "in training loop, epoch 1, step 127, the loss is 736915.5\n",
            "in training loop, epoch 1, step 128, the loss is 639720.125\n",
            "in training loop, epoch 1, step 129, the loss is 1292750.0\n",
            "in training loop, epoch 1, step 130, the loss is 2185776.75\n",
            "in training loop, epoch 1, step 131, the loss is 697034.6875\n",
            "in training loop, epoch 1, step 132, the loss is 454058.03125\n",
            "in training loop, epoch 1, step 133, the loss is 607833.4375\n",
            "in training loop, epoch 1, step 134, the loss is 484554.1875\n",
            "in training loop, epoch 1, step 135, the loss is 876792.75\n",
            "in training loop, epoch 1, step 136, the loss is 753649.6875\n",
            "in training loop, epoch 1, step 137, the loss is 596018.0625\n",
            "in training loop, epoch 1, step 138, the loss is 470592.46875\n",
            "in training loop, epoch 1, step 139, the loss is 425754.625\n",
            "in training loop, epoch 1, step 140, the loss is 1364347.625\n",
            "in training loop, epoch 1, step 141, the loss is 634944.9375\n",
            "in training loop, epoch 1, step 142, the loss is 1655749.375\n",
            "in training loop, epoch 1, step 143, the loss is 191893.84375\n",
            "in training loop, epoch 1, step 144, the loss is 2817423.0\n",
            "in training loop, epoch 1, step 145, the loss is 828891.3125\n",
            "in training loop, epoch 1, step 146, the loss is 360547.15625\n",
            "in training loop, epoch 1, step 147, the loss is 593129.6875\n",
            "in training loop, epoch 1, step 148, the loss is 1432335.375\n",
            "in training loop, epoch 1, step 149, the loss is 804278.125\n",
            "in training loop, epoch 1, step 150, the loss is 526897.75\n",
            "in training loop, epoch 1, step 151, the loss is 458696.8125\n",
            "in training loop, epoch 1, step 152, the loss is 267722.96875\n",
            "in training loop, epoch 1, step 153, the loss is 1308199.125\n",
            "in training loop, epoch 1, step 154, the loss is 291191.375\n",
            "in training loop, epoch 1, step 155, the loss is 1025769.4375\n",
            "in training loop, epoch 1, step 156, the loss is 456723.59375\n",
            "in training loop, epoch 1, step 157, the loss is 419236.3125\n",
            "in training loop, epoch 1, step 158, the loss is 198275.453125\n",
            "in training loop, epoch 1, step 159, the loss is 666969.25\n",
            "in training loop, epoch 1, step 160, the loss is 362332.53125\n",
            "in training loop, epoch 1, step 161, the loss is 748304.5625\n",
            "in training loop, epoch 1, step 162, the loss is 448885.75\n",
            "in training loop, epoch 1, step 163, the loss is 1303457.875\n",
            "in training loop, epoch 1, step 164, the loss is 206602.078125\n",
            "in training loop, epoch 1, step 165, the loss is 376010.875\n",
            "in training loop, epoch 1, step 166, the loss is 357048.625\n",
            "in training loop, epoch 1, step 167, the loss is 164074.28125\n",
            "in training loop, epoch 1, step 168, the loss is 827642.125\n",
            "in training loop, epoch 1, step 169, the loss is 624238.5\n",
            "in training loop, epoch 1, step 170, the loss is 199815.0\n",
            "in training loop, epoch 1, step 171, the loss is 276039.15625\n",
            "in training loop, epoch 1, step 172, the loss is 474553.9375\n",
            "in training loop, epoch 1, step 173, the loss is 719812.0625\n",
            "in training loop, epoch 1, step 174, the loss is 125028.703125\n",
            "in training loop, epoch 1, step 175, the loss is 515800.75\n",
            "in training loop, epoch 1, step 176, the loss is 332542.21875\n",
            "in training loop, epoch 1, step 177, the loss is 1062902.375\n",
            "in training loop, epoch 1, step 178, the loss is 722938.1875\n",
            "in training loop, epoch 1, step 179, the loss is 1002101.125\n",
            "in training loop, epoch 1, step 180, the loss is 557963.0625\n",
            "in training loop, epoch 1, step 181, the loss is 386401.71875\n",
            "in training loop, epoch 1, step 182, the loss is 195107.8125\n",
            "in training loop, epoch 1, step 183, the loss is 436267.90625\n",
            "in training loop, epoch 1, step 184, the loss is 1754334.5\n",
            "in training loop, epoch 1, step 185, the loss is 1505341.75\n",
            "in training loop, epoch 1, step 186, the loss is 319760.09375\n",
            "in training loop, epoch 1, step 187, the loss is 169392.078125\n",
            "in training loop, epoch 1, step 188, the loss is 276024.65625\n",
            "in training loop, epoch 1, step 189, the loss is 703197.5\n",
            "in training loop, epoch 1, step 190, the loss is 491697.0\n",
            "in training loop, epoch 1, step 191, the loss is 616189.9375\n",
            "in training loop, epoch 1, step 192, the loss is 647950.875\n",
            "in training loop, epoch 1, step 193, the loss is 414488.3125\n",
            "in training loop, epoch 1, step 194, the loss is 390672.59375\n",
            "in training loop, epoch 1, step 195, the loss is 312940.59375\n",
            "in training loop, epoch 1, step 196, the loss is 165197.1875\n",
            "in training loop, epoch 1, step 197, the loss is 1241918.375\n",
            "in training loop, epoch 1, step 198, the loss is 300163.1875\n",
            "in training loop, epoch 1, step 199, the loss is 198232.96875\n",
            "in training loop, epoch 1, step 200, the loss is 331202.40625\n",
            "in training loop, epoch 1, step 201, the loss is 186961.1875\n",
            "in training loop, epoch 1, step 202, the loss is 739597.9375\n",
            "in training loop, epoch 1, step 203, the loss is 576958.25\n",
            "in training loop, epoch 1, step 204, the loss is 449795.625\n",
            "in training loop, epoch 1, step 205, the loss is 586000.8125\n",
            "in training loop, epoch 1, step 206, the loss is 426452.28125\n",
            "in training loop, epoch 1, step 207, the loss is 320827.875\n",
            "in training loop, epoch 1, step 208, the loss is 299423.96875\n",
            "in training loop, epoch 1, step 209, the loss is 151427.203125\n",
            "in training loop, epoch 1, step 210, the loss is 206807.25\n",
            "in training loop, epoch 1, step 211, the loss is 728562.5\n",
            "in training loop, epoch 1, step 212, the loss is 1336305.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3I63RgNmk73"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}