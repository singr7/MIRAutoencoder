{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singr7/MIRAutoencoder/blob/master/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9xFmHrsk23y"
      },
      "source": [
        "# Variational AutoEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOv74I02k233"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fpFMsj5zk234"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.layers\n",
        "import tensorflow.keras.models\n",
        "import tensorflow.keras.optimizers\n",
        "import tensorflow.keras.datasets\n",
        "import numpy\n",
        "import matplotlib.pyplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnxAlvtuk235"
      },
      "source": [
        "## Create the encoding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "br2K6FmFk235"
      },
      "outputs": [],
      "source": [
        "num_channels=1\n",
        "feature_size_1= 96\n",
        "feature_size_2 = 200\n",
        "latent_space_dim =2 \n",
        "# Encoder\n",
        "x = tensorflow.keras.layers.Input(shape=(feature_size_1, feature_size_2, num_channels), name=\"encoder_input\")\n",
        "\n",
        "encoder_conv_layer1 = tensorflow.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"encoder_conv_1\")(x)\n",
        "encoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n",
        "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_norm_layer1)\n",
        "\n",
        "encoder_conv_layer2 = tensorflow.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_2\")(encoder_activ_layer1)\n",
        "encoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_2\")(encoder_conv_layer2)\n",
        "encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_2\")(encoder_norm_layer2)\n",
        "\n",
        "encoder_conv_layer3 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_3\")(encoder_activ_layer2)\n",
        "encoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_3\")(encoder_conv_layer3)\n",
        "encoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_3\")(encoder_norm_layer3)\n",
        "\n",
        "encoder_conv_layer4 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_4\")(encoder_activ_layer3)\n",
        "encoder_norm_layer4 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_4\")(encoder_conv_layer4)\n",
        "encoder_activ_layer4 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_4\")(encoder_norm_layer4)\n",
        "\n",
        "encoder_conv_layer5 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_5\")(encoder_activ_layer4)\n",
        "encoder_norm_layer5 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_5\")(encoder_conv_layer5)\n",
        "encoder_activ_layer5 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_5\")(encoder_norm_layer5)\n",
        "\n",
        "shape_before_flatten = tensorflow.keras.backend.int_shape(encoder_activ_layer5)[1:]\n",
        "encoder_flatten = tensorflow.keras.layers.Flatten()(encoder_activ_layer5)\n",
        "\n",
        "encoder_mu = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_mu\")(encoder_flatten)\n",
        "encoder_log_variance = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(encoder_flatten)\n",
        "\n",
        "encoder_mu_log_variance_model = tensorflow.keras.models.Model(x, (encoder_mu, encoder_log_variance), name=\"encoder_mu_log_variance_model\")\n",
        "\n",
        "def sampling(mu_log_variance):\n",
        "    mu, log_variance = mu_log_variance\n",
        "    epsilon = tensorflow.keras.backend.random_normal(shape=tensorflow.keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
        "    random_sample = mu + tensorflow.keras.backend.exp(log_variance/2) * epsilon\n",
        "    return random_sample\n",
        "\n",
        "encoder_output = tensorflow.keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
        "\n",
        "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoUVUV4vk236"
      },
      "source": [
        "## Build the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69L55reLk236",
        "outputId": "9ae15d03-f151-424f-e978-2fe7454f4e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 96, 200, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder_conv_1 (Conv2D)        (None, 96, 200, 1)   10          ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_norm_1 (BatchNormaliza  (None, 96, 200, 1)  4           ['encoder_conv_1[0][0]']         \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_leakyrelu_1 (LeakyReLU  (None, 96, 200, 1)  0           ['encoder_norm_1[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_conv_2 (Conv2D)        (None, 96, 200, 32)  320         ['encoder_leakyrelu_1[0][0]']    \n",
            "                                                                                                  \n",
            " encoder_norm_2 (BatchNormaliza  (None, 96, 200, 32)  128        ['encoder_conv_2[0][0]']         \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_activ_layer_2 (LeakyRe  (None, 96, 200, 32)  0          ['encoder_norm_2[0][0]']         \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_3 (Conv2D)        (None, 48, 100, 64)  18496       ['encoder_activ_layer_2[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_norm_3 (BatchNormaliza  (None, 48, 100, 64)  256        ['encoder_conv_3[0][0]']         \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_activ_layer_3 (LeakyRe  (None, 48, 100, 64)  0          ['encoder_norm_3[0][0]']         \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_4 (Conv2D)        (None, 24, 50, 64)   36928       ['encoder_activ_layer_3[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_norm_4 (BatchNormaliza  (None, 24, 50, 64)  256         ['encoder_conv_4[0][0]']         \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_activ_layer_4 (LeakyRe  (None, 24, 50, 64)  0           ['encoder_norm_4[0][0]']         \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_5 (Conv2D)        (None, 24, 50, 64)   36928       ['encoder_activ_layer_4[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_norm_5 (BatchNormaliza  (None, 24, 50, 64)  256         ['encoder_conv_5[0][0]']         \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_activ_layer_5 (LeakyRe  (None, 24, 50, 64)  0           ['encoder_norm_5[0][0]']         \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 76800)        0           ['encoder_activ_layer_5[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_mu (Dense)             (None, 2)            153602      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " encoder_log_variance (Dense)   (None, 2)            153602      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " encoder_output (Lambda)        (None, 2)            0           ['encoder_mu[0][0]',             \n",
            "                                                                  'encoder_log_variance[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 400,786\n",
            "Trainable params: 400,336\n",
            "Non-trainable params: 450\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kWdD51dk237"
      },
      "source": [
        "## Build the decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkCxEamxk237",
        "outputId": "055effb2-de7a-45bb-ab7c-8ed5376757c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " decoder_dense_1 (Dense)     (None, 76800)             230400    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 24, 50, 64)        0         \n",
            "                                                                 \n",
            " decoder_conv_tran_1 (Conv2D  (None, 24, 50, 64)       36928     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " decoder_norm_1 (BatchNormal  (None, 24, 50, 64)       256       \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " decoder_leakyrelu_1 (LeakyR  (None, 24, 50, 64)       0         \n",
            " eLU)                                                            \n",
            "                                                                 \n",
            " decoder_conv_tran_2 (Conv2D  (None, 48, 100, 64)      36928     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " decoder_norm_2 (BatchNormal  (None, 48, 100, 64)      256       \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " decoder_leakyrelu_2 (LeakyR  (None, 48, 100, 64)      0         \n",
            " eLU)                                                            \n",
            "                                                                 \n",
            " decoder_conv_tran_3 (Conv2D  (None, 96, 200, 64)      36928     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " decoder_norm_3 (BatchNormal  (None, 96, 200, 64)      256       \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " decoder_leakyrelu_3 (LeakyR  (None, 96, 200, 64)      0         \n",
            " eLU)                                                            \n",
            "                                                                 \n",
            " decoder_conv_tran_4 (Conv2D  (None, 96, 200, 1)       577       \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " decoder_output (LeakyReLU)  (None, 96, 200, 1)        0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 342,529\n",
            "Trainable params: 342,145\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "decoder_input = tensorflow.keras.layers.Input(shape=(latent_space_dim), name=\"decoder_input\")\n",
        "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=numpy.prod(shape_before_flatten), name=\"decoder_dense_1\")(decoder_input)\n",
        "\n",
        "decoder_reshape = tensorflow.keras.layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer1)\n",
        "\n",
        "decoder_conv_tran_layer1 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"decoder_conv_tran_1\")(decoder_reshape)\n",
        "decoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_1\")(decoder_conv_tran_layer1)\n",
        "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_norm_layer1)\n",
        "\n",
        "decoder_conv_tran_layer2 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_2\")(decoder_activ_layer1)\n",
        "decoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_2\")(decoder_conv_tran_layer2)\n",
        "decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_norm_layer2)\n",
        "\n",
        "decoder_conv_tran_layer3 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_3\")(decoder_activ_layer2)\n",
        "decoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_3\")(decoder_conv_tran_layer3)\n",
        "decoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_norm_layer3)\n",
        "\n",
        "decoder_conv_tran_layer4 = tensorflow.keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"decoder_conv_tran_4\")(decoder_activ_layer3)\n",
        "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_output\")(decoder_conv_tran_layer4 )\n",
        "\n",
        "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
        "\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VngVDmfKp1qw"
      },
      "outputs": [],
      "source": [
        "def loss_func(encoder_mu, encoder_log_variance):\n",
        "    def vae_reconstruction_loss(y_true, y_predict):\n",
        "        reconstruction_loss_factor = 1000\n",
        "        reconstruction_loss = tensorflow.keras.backend.mean(tensorflow.keras.backend.square(y_true-y_predict), axis=[1, 2, 3])\n",
        "        return reconstruction_loss_factor * reconstruction_loss\n",
        "\n",
        "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
        "        kl_loss = -0.5 * tensorflow.keras.backend.sum(1.0 + encoder_log_variance - tensorflow.keras.backend.square(encoder_mu) - tensorflow.keras.backend.exp(encoder_log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_kl_loss_metric(y_true, y_predict):\n",
        "        kl_loss = -0.5 * tensorflow.keras.backend.sum(1.0 + encoder_log_variance - tensorflow.keras.backend.square(encoder_mu) - tensorflow.keras.backend.exp(encoder_log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_loss(y_true, y_predict):\n",
        "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
        "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
        "\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        return loss\n",
        "\n",
        "    return vae_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3awfbtRk238"
      },
      "source": [
        "## Define the VAE as a `Model` with a custom `train_step`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h59DQTk9k239",
        "outputId": "2323affa-be74-4a33-b092-ada9afb6b850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"VAE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " VAE_input (InputLayer)      [(None, 96, 200, 1)]      0         \n",
            "                                                                 \n",
            " encoder_model (Functional)  (None, 2)                 400786    \n",
            "                                                                 \n",
            " decoder_model (Functional)  (None, 96, 200, 1)        342529    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 743,315\n",
            "Trainable params: 742,481\n",
            "Non-trainable params: 834\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vae_input = tensorflow.keras.layers.Input(shape=(96, 200, num_channels), name=\"VAE_input\")\n",
        "vae_encoder_output = encoder(vae_input)\n",
        "vae_decoder_output = decoder(vae_encoder_output)\n",
        "vae = tensorflow.keras.models.Model(vae_input, vae_decoder_output, name=\"VAE\")\n",
        "\n",
        "vae.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0005), loss=loss_func(encoder_mu, encoder_log_variance), metrics=[tensorflow.keras.metrics.Accuracy()])\n",
        "\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw3bf1rjrESX",
        "outputId": "2e805c2e-d11c-43eb-800d-67074fa9cea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Get the input data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKuyVXzirRMR",
        "outputId": "7085956d-bb8e-442b-c6ca-7b8de3a7de0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3117"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import glob\n",
        "feature_set =[]\n",
        "files = glob.glob('/content/drive/My Drive/MusicResearch/vajra/dataset/96_features/96_MelFeatures/96_GTZANMel/**/*', recursive=True)\n",
        "count=0\n",
        "for file in files:\n",
        "  f= np.load(file)\n",
        "  feature_set.append([f,0])\n",
        "\n",
        "len(feature_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-AVhdx0rjAT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(feature_set)\n",
        "\n",
        "import pickle \n",
        "os.chdir('/content/drive/My Drive/MusicResearch/vajra/dataset/96_features/96_MelFeatures/')\n",
        "data_pickle = open('Mel_OnlyGTZANData.pickle','wb')\n",
        "pickle.dump(feature_set,data_pickle)\n",
        "data_pickle.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TmL0I42zrker"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/My Drive/MusicResearch/vajra/dataset/96_features/96_MelFeatures/')\n",
        "import pickle\n",
        "data_pickle = open('Mel_OnlyGTZANData.pickle','rb')\n",
        "data = pickle.load(data_pickle)\n",
        "data_pickle.close()\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for feature, label in data:\n",
        "  features.append(feature)\n",
        "  labels.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KIIZkJLvjBO",
        "outputId": "aebc810c-1e0a-4c74-d7c7-cc824d6206a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3117"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHY7rFoqqKhd",
        "outputId": "1e13bd23-9dd4-4ff7-fa58-9467b8494da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2805, 96, 200)\n",
            "(2805, 96, 200, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.1)\n",
        "x_train = np.asarray(x_train, dtype=np.float32)\n",
        "x_test = np.asarray(x_test, dtype=np.float32)\n",
        "print(x_train.shape)\n",
        "x_train = numpy.reshape(x_train, newshape=(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)) \n",
        "x_test = numpy.reshape(x_test, newshape=(x_test.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(x):\n",
        "    mean = np.mean(x, axis=0)\n",
        "    std = np.std(x, axis=0)+0.000001\n",
        "    X_train = (x - mean) / std\n",
        "    return X_train\n",
        "  "
      ],
      "metadata": {
        "id": "KsCSXHkf_7g2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = standardize(x_train)\n",
        "X_test = standardize(x_test)\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBeX4MSSAg1a",
        "outputId": "51d53fe2-9126-4aa2-abd1-cd43fbaea749"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2805, 96, 200, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.any(np.isnan(X_train)))\n",
        "print(np.any(np.isnan(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vLf4dPU_2Nn",
        "outputId": "5596bd8f-0b44-4d18-e41b-69ddc19dd0af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEMEQAZpk239"
      },
      "source": [
        "## Train the VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPYa_vt7k23-",
        "outputId": "06e514ef-fdfc-4b4c-f25d-581be7c46fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "88/88 [==============================] - 391s 4s/step - loss: 1721049.3750 - accuracy: 0.0000e+00 - val_loss: 1737327.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 390s 4s/step - loss: 1447103.2500 - accuracy: 0.0000e+00 - val_loss: 1530255.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 392s 4s/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 393s 4s/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 399s 5s/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 402s 5s/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 407s 5s/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 409s 5s/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 409s 5s/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            " 2/88 [..............................] - ETA: 6:26 - loss: nan - accuracy: 0.0000e+00"
          ]
        }
      ],
      "source": [
        "history= vae.fit(x_train, x_train, epochs=20, batch_size=32, shuffle=True, validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmoSGx9jwRKy",
        "outputId": "c370c7c6-da65-4f09-f17e-1d2116582c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "encoder.save(\"VAE_GTZANencoder.h5\") \n",
        "decoder.save(\"VAE_GTZANdecoder.h5\") \n",
        "vae.save(\"VAE_GTZAN.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d11v6X8LKGFx",
        "outputId": "daf9e527-9a18-462b-ea64-59d1573bfaf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "encoder = tensorflow.keras.models.load_model(\"VAE_GTZANencoder.h5\") \n",
        "decoder = tensorflow.keras.models.load_model(\"VAE_GTZANdecoder.h5\")\n",
        "vae_model =tensorflow.keras.models.load_model(\"VAE_GTZAN.h5\",custom_objects={'vae_loss': loss_func(encoder_mu=0.0,encoder_log_variance=1.0)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k88yznVuKrGI"
      },
      "outputs": [],
      "source": [
        "encoded_data = encoder.predict(x_test)\n",
        "decoded_data = decoder.predict(encoded_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn2_cjbqCawd",
        "outputId": "e0b3fe11-2cea-49d0-cd45-9dcafd2d6e3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keract\n",
            "  Downloading keract-4.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Installing collected packages: keract\n",
            "Successfully installed keract-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keract"
      ],
      "metadata": {
        "id": "4WCNVKkkNPqD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the fmri dataset\n",
        "import pickle\n",
        "data_pickle = open('/content/drive/My Drive/MusicResearch/vajra/dataset/fmri_songs_numpy/fmri_96_mel_numpy/Mel_fMRIStream7minData.pickle','rb')\n",
        "fmri_data = pickle.load(data_pickle)\n",
        "data_pickle.close()\n",
        "\n",
        "x_fmri_stream = []\n",
        "labels = []\n",
        "\n",
        "for feature, label in fmri_data:\n",
        "  x_fmri_stream.append(feature)\n",
        "  labels.append(label)\n",
        "\n",
        "x_fmri_stream= np.asarray(x_fmri_stream)\n",
        "x_fmri_stream = np.reshape(x_fmri_stream, newshape=(x_fmri_stream.shape[0], x_fmri_stream.shape[1], x_fmri_stream.shape[2], 1))\n",
        "X_fmri_stream= standardize(x_fmri_stream)\n",
        "X_fmri_stream.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii1vu9pYDYVU",
        "outputId": "f8d427e1-93d2-4eaa-f4f9-48c6e3feb0be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46, 96, 200, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activations = keract.get_activations(encoder, x_fmri_stream, layer_names=['encoder_conv_1','encoder_activ_layer_2','encoder_activ_layer_3', 'encoder_activ_layer_4','encoder_activ_layer_5'] ,auto_compile=True)\n",
        "\n",
        "# print the activations shapes.\n",
        "[print(k, '->', v.shape, '- Numpy array') for (k, v) in activations.items()]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imWPfD0rDHAu",
        "outputId": "e58d0852-96dd-4401-832a-42bf5cd180d9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_conv_1 -> (46, 96, 200, 1) - Numpy array\n",
            "encoder_activ_layer_2 -> (46, 96, 200, 32) - Numpy array\n",
            "encoder_activ_layer_3 -> (46, 48, 100, 64) - Numpy array\n",
            "encoder_activ_layer_4 -> (46, 24, 50, 64) - Numpy array\n",
            "encoder_activ_layer_5 -> (46, 24, 50, 64) - Numpy array\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename='/content/drive/My Drive/MusicResearch/vajra/dataset/fmri_songs_numpy/fmri_96_mel_numpy/fmri_activations_stream7_GTZANAE.json'\n",
        "keract.persist_to_json_file(activations, filename)"
      ],
      "metadata": {
        "id": "ZOeO0bPUPN3Z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_activations= keract.load_activations_from_json_file(filename)"
      ],
      "metadata": {
        "id": "pGC95CJrPqYF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keract.display_activations(activations, cmap=None, save=False, directory='.', data_format='channels_last', fig_size=(24, 24), reshape_1d_layers=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1aZKyiVMUxI",
        "outputId": "e4d4f601-5cbc-437c-84ee-c365fa3168ef"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_conv_1 (46, 96, 200, 1) -> Skipped. First dimension is not 1.\n",
            "encoder_activ_layer_2 (46, 96, 200, 32) -> Skipped. First dimension is not 1.\n",
            "encoder_activ_layer_3 (46, 48, 100, 64) -> Skipped. First dimension is not 1.\n",
            "encoder_activ_layer_4 (46, 24, 50, 64) -> Skipped. First dimension is not 1.\n",
            "encoder_activ_layer_5 (46, 24, 50, 64) -> Skipped. First dimension is not 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keract.display_heatmaps(activations, input_image, save=False)"
      ],
      "metadata": {
        "id": "jtdjYMbqMW03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "WzdgD1pgLxUF",
        "outputId": "d4aa4209-77b4-4be2-c377-696c4e6b2531"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-adcbba80ebb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "UKo6iICDY-pz",
        "outputId": "a394df5d-aa84-4250-ad44-01c57650cd1a"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-04d7c6908c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
          ]
        }
      ],
      "source": [
        "vae_model.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W7u3Dulk23-"
      },
      "source": [
        "## Display a grid of sampled digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyRE8tIxk23-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_latent_space(vae, n=30, figsize=15):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    digit_size = 28\n",
        "    scale = 1.0\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = vae.decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "            ] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latent_space(vae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMQcs12k23_"
      },
      "source": [
        "## Display how the latent space clusters different digit classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKmpv0eBk23_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_label_clusters(vae, data, labels):\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "\n",
        "plot_label_clusters(vae, x_train, y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "VAE",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}